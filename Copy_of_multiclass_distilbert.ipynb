{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCSvpHMWJ0Ky",
        "outputId": "5d20bf37-06ce-439b-9a0a-eddae9664444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install beautifulsoup4\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm # Progress Bar\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import warnings\n",
        "from transformers import logging as hf_logging\n",
        "hf_logging.set_verbosity_error() # Hidding Huggingface Warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'distilbert-base-cased'\n"
      ],
      "metadata": {
        "id": "pNjk-75-PjnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "4Q478fHPPU5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train.csv')"
      ],
      "metadata": {
        "id": "-FtssIZ9J34I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkEdhiybKzmJ",
        "outputId": "69ced2ca-24b8-4558-999f-ab37f96201b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8VbhDazL67v",
        "outputId": "1c3ffb27-e1c9-4b6f-ebb1-25e03ff54f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number\n",
        "\n",
        "import string\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    stop_words = list(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stop_words:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)\n",
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc\n",
        "def lemmatizing(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
        "        tokens[i] = lemma_word\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "T6bVdrfQMIax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate columns as strings\n",
        "df['Combined'] = df['post_text'].astype(str) + df['pre_text'].astype(str) + df['table'].astype(str)\n",
        "\n",
        "df['Combined_clean'] = df['Combined'].apply(lambda x: convert_to_lower(x))\n",
        "df['Lenght_before'] = df['Combined_clean'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "kA7W4U7CMPjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Combined_clean'] = df['Combined_clean'].apply(lambda x: remove_numbers(x))\n",
        "df['Combined_clean'] = df['Combined_clean'].apply(lambda x: remove_punctuation(x))\n",
        "df['Combined_clean'] = df['Combined_clean'].apply(lambda x: remove_stopwords(x))\n",
        "df['Combined_clean'] = df['Combined_clean'].apply(lambda x: remove_extra_white_spaces(x))\n",
        "df['Lenght_after'] = df['Combined_clean'].apply(lambda x: len(x))\n"
      ],
      "metadata": {
        "id": "gRV4JI82N1Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['industry_label'] = le.fit_transform(df['industry'])"
      ],
      "metadata": {
        "id": "a-jFLPxIPrQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Perform sentiment analysis on each text in the dataset\n",
        "sentiments = []\n",
        "for text in df['text']:\n",
        "    # Get the polarity scores\n",
        "    scores = sid.polarity_scores(text)\n",
        "\n",
        "    # Determine the sentiment label based on the compound score\n",
        "    if scores['compound'] >= 0.05:\n",
        "        sentiment = 'Positive'\n",
        "    elif scores['compound'] <= -0.05:\n",
        "        sentiment = 'Negative'\n",
        "    else:\n",
        "        sentiment = 'Neutral'\n",
        "\n",
        "    # Append the sentiment label to the list\n",
        "    sentiments.append(sentiment)\n",
        "\n",
        "# Add the sentiment labels to the dataframe\n",
        "df['sentiment'] = sentiments\n",
        "\n",
        "# Print the dataframe with sentiment labels\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "CK2VCe-wO5p9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "9676f4e8-e059-4af2-9f15-08428b31af0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-6b10c07ae0e7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Perform sentiment analysis on each text in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lexicon_file)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mlexicon_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     ):\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_lex_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVaderConstants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "tf_wb= TfidfVectorizer()\n",
        "X_tf = tf_wb.fit_transform(df['Combined_clean'])\n",
        "X_tf = X_tf.toarray()"
      ],
      "metadata": {
        "id": "yG3sBFdpQU1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n"
      ],
      "metadata": {
        "id": "udIFGa8e9Uhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tFW42VYZ9a5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "jPVWUWLo-McC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna"
      ],
      "metadata": {
        "id": "0_Bi5jcE_myx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d06eb966-bea7-4a61-d5de-1298ca09810f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.dropna of                            id  \\\n",
              "0       EW/2016/page_50.pdf-2   \n",
              "1     ETR/2016/page_352.pdf-3   \n",
              "2      GS/2012/page_186.pdf-3   \n",
              "3      ADI/2011/page_83.pdf-2   \n",
              "4     PNC/2014/page_203.pdf-3   \n",
              "...                       ...   \n",
              "1967    GS/2015/page_76.pdf-3   \n",
              "1968  JPM/2009/page_238.pdf-2   \n",
              "1969   AES/2001/page_45.pdf-2   \n",
              "1970  ETR/2017/page_175.pdf-3   \n",
              "1971   STT/2006/page_96.pdf-4   \n",
              "\n",
              "                                              post_text  \\\n",
              "0     ['( a ) the amount included in 2018 2018less t...   \n",
              "1     ['see note 4 to the financial statements for a...   \n",
              "2     ['rwas under the federal reserve board 2019s r...   \n",
              "3     ['12 .'\\n 'commitments and contingencies from ...   \n",
              "4     ['the pnc financial services group , inc .' '2...   \n",
              "...                                                 ...   \n",
              "1967  ['1 .'\\n 'net revenues related to our consolid...   \n",
              "1968  ['non-u.s. ( a ) 9804 4867 9085 income before ...   \n",
              "1969  ['* includes venezuela and colombia .'\\n 'sell...   \n",
              "1970  ['entergy corporation and subsidiaries notes t...   \n",
              "1971  ['compensation expense related to stock option...   \n",
              "\n",
              "                                               pre_text  \\\n",
              "0     ['net cash flows provided by operating activit...   \n",
              "1     ['entergy louisiana , llc and subsidiaries man...   \n",
              "2     ['notes to consolidated financial statements n...   \n",
              "3     ['the following is a schedule of future minimu...   \n",
              "4     ['to determine stock-based compensation expens...   \n",
              "...                                                 ...   \n",
              "1967  ['the goldman sachs group , inc .'\\n 'and subs...   \n",
              "1968  ['notes to consolidated financial statements j...   \n",
              "1969  ['of sales , competitive supply gross margin d...   \n",
              "1970  ['as of december a031 , 2017 , system energy ,...   \n",
              "1971  ['for the year ended december 31 , 2005 , we r...   \n",
              "\n",
              "                                                  table        industry  \\\n",
              "0     [array(['contractual obligations', 'payments d...  Pharmaceutical   \n",
              "1     [array(['2016', '2015', '2014', '2013'], dtype...          Energy   \n",
              "2     [array(['$ in millions', 'as of december 2012'...         Finance   \n",
              "3     [array(['fiscal years', 'operating leases'], d...      Technology   \n",
              "4     [array(['shares in thousands december 31 2013'...         Finance   \n",
              "...                                                 ...             ...   \n",
              "1967  [array(['$ in millions', 'year ended december ...         Finance   \n",
              "1968  [array(['year ended december 31 ( in millions ...         Finance   \n",
              "1969  [array(['north america', '2001 $ 912 million',...          Energy   \n",
              "1970  [array(['', 'amount ( in thousands )'], dtype=...          Energy   \n",
              "1971  [array(['', '2006', '2005', '2004'], dtype=obj...         Finance   \n",
              "\n",
              "                                               Combined  \\\n",
              "0     ['( a ) the amount included in 2018 2018less t...   \n",
              "1     ['see note 4 to the financial statements for a...   \n",
              "2     ['rwas under the federal reserve board 2019s r...   \n",
              "3     ['12 .'\\n 'commitments and contingencies from ...   \n",
              "4     ['the pnc financial services group , inc .' '2...   \n",
              "...                                                 ...   \n",
              "1967  ['1 .'\\n 'net revenues related to our consolid...   \n",
              "1968  ['non-u.s. ( a ) 9804 4867 9085 income before ...   \n",
              "1969  ['* includes venezuela and colombia .'\\n 'sell...   \n",
              "1970  ['entergy corporation and subsidiaries notes t...   \n",
              "1971  ['compensation expense related to stock option...   \n",
              "\n",
              "                                         Combined_clean  Lenght_before  \\\n",
              "0     amount included less year reflects anticipated...           4184   \n",
              "1     see note financial statements description mone...           4099   \n",
              "2     rwas federal reserve board riskbased capital r...           4750   \n",
              "3     commitments contingencies time time ordinary c...           2873   \n",
              "4     pnc financial services group inc form determin...           5241   \n",
              "...                                                 ...            ...   \n",
              "1967  net revenues related consolidated investments ...           4611   \n",
              "1968  nonus income income tax expense benefit extrao...           5487   \n",
              "1969  includes venezuela colombia selling general ad...           4080   \n",
              "1970  entergy corporation subsidiaries notes financi...           4269   \n",
              "1971  compensation expense related stock options sto...           4395   \n",
              "\n",
              "      Lenght_after  industry_label  \n",
              "0             2542               2  \n",
              "1             2876               0  \n",
              "2             3197               1  \n",
              "3             1862               3  \n",
              "4             3457               1  \n",
              "...            ...             ...  \n",
              "1967          3130               1  \n",
              "1968          3626               1  \n",
              "1969          2379               0  \n",
              "1970          3049               0  \n",
              "1971          2675               1  \n",
              "\n",
              "[1972 rows x 10 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame.dropna</b><br/>def dropna(*, axis: Axis=0, how: AnyAll | NoDefault=no_default, thresh: int | NoDefault=no_default, subset: IndexLabel=None, inplace: bool=False, ignore_index: bool=False) -&gt; DataFrame | None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Remove missing values.\n",
              "\n",
              "See the :ref:`User Guide &lt;missing_data&gt;` for more on which values are\n",
              "considered missing, and how to work with missing data.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "axis : {0 or &#x27;index&#x27;, 1 or &#x27;columns&#x27;}, default 0\n",
              "    Determine if rows or columns which contain missing values are\n",
              "    removed.\n",
              "\n",
              "    * 0, or &#x27;index&#x27; : Drop rows which contain missing values.\n",
              "    * 1, or &#x27;columns&#x27; : Drop columns which contain missing value.\n",
              "\n",
              "    Pass tuple or list to drop on multiple axes.\n",
              "    Only a single axis is allowed.\n",
              "\n",
              "how : {&#x27;any&#x27;, &#x27;all&#x27;}, default &#x27;any&#x27;\n",
              "    Determine if row or column is removed from DataFrame, when we have\n",
              "    at least one NA or all NA.\n",
              "\n",
              "    * &#x27;any&#x27; : If any NA values are present, drop that row or column.\n",
              "    * &#x27;all&#x27; : If all values are NA, drop that row or column.\n",
              "\n",
              "thresh : int, optional\n",
              "    Require that many non-NA values. Cannot be combined with how.\n",
              "subset : column label or sequence of labels, optional\n",
              "    Labels along other axis to consider, e.g. if you are dropping rows\n",
              "    these would be a list of columns to include.\n",
              "inplace : bool, default False\n",
              "    Whether to modify the DataFrame rather than creating a new one.\n",
              "ignore_index : bool, default ``False``\n",
              "    If ``True``, the resulting axis will be labeled 0, 1, …, n - 1.\n",
              "\n",
              "    .. versionadded:: 2.0.0\n",
              "\n",
              "Returns\n",
              "-------\n",
              "DataFrame or None\n",
              "    DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.isna: Indicate missing values.\n",
              "DataFrame.notna : Indicate existing (non-missing) values.\n",
              "DataFrame.fillna : Replace missing values.\n",
              "Series.dropna : Drop missing values.\n",
              "Index.dropna : Drop missing indices.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&quot;name&quot;: [&#x27;Alfred&#x27;, &#x27;Batman&#x27;, &#x27;Catwoman&#x27;],\n",
              "...                    &quot;toy&quot;: [np.nan, &#x27;Batmobile&#x27;, &#x27;Bullwhip&#x27;],\n",
              "...                    &quot;born&quot;: [pd.NaT, pd.Timestamp(&quot;1940-04-25&quot;),\n",
              "...                             pd.NaT]})\n",
              "&gt;&gt;&gt; df\n",
              "       name        toy       born\n",
              "0    Alfred        NaN        NaT\n",
              "1    Batman  Batmobile 1940-04-25\n",
              "2  Catwoman   Bullwhip        NaT\n",
              "\n",
              "Drop the rows where at least one element is missing.\n",
              "\n",
              "&gt;&gt;&gt; df.dropna()\n",
              "     name        toy       born\n",
              "1  Batman  Batmobile 1940-04-25\n",
              "\n",
              "Drop the columns where at least one element is missing.\n",
              "\n",
              "&gt;&gt;&gt; df.dropna(axis=&#x27;columns&#x27;)\n",
              "       name\n",
              "0    Alfred\n",
              "1    Batman\n",
              "2  Catwoman\n",
              "\n",
              "Drop the rows where all elements are missing.\n",
              "\n",
              "&gt;&gt;&gt; df.dropna(how=&#x27;all&#x27;)\n",
              "       name        toy       born\n",
              "0    Alfred        NaN        NaT\n",
              "1    Batman  Batmobile 1940-04-25\n",
              "2  Catwoman   Bullwhip        NaT\n",
              "\n",
              "Keep only the rows with at least 2 non-NA values.\n",
              "\n",
              "&gt;&gt;&gt; df.dropna(thresh=2)\n",
              "       name        toy       born\n",
              "1    Batman  Batmobile 1940-04-25\n",
              "2  Catwoman   Bullwhip        NaT\n",
              "\n",
              "Define in which columns to look for missing values.\n",
              "\n",
              "&gt;&gt;&gt; df.dropna(subset=[&#x27;name&#x27;, &#x27;toy&#x27;])\n",
              "       name        toy       born\n",
              "1    Batman  Batmobile 1940-04-25\n",
              "2  Catwoman   Bullwhip        NaT</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 6274);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "8EIY0TdtM9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "43e35b3a-39f8-4d0a-99d3-ed67c4f748ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id                                          post_text  \\\n",
              "0    EW/2016/page_50.pdf-2  ['( a ) the amount included in 2018 2018less t...   \n",
              "1  ETR/2016/page_352.pdf-3  ['see note 4 to the financial statements for a...   \n",
              "2   GS/2012/page_186.pdf-3  ['rwas under the federal reserve board 2019s r...   \n",
              "3   ADI/2011/page_83.pdf-2  ['12 .'\\n 'commitments and contingencies from ...   \n",
              "4  PNC/2014/page_203.pdf-3  ['the pnc financial services group , inc .' '2...   \n",
              "\n",
              "                                            pre_text  \\\n",
              "0  ['net cash flows provided by operating activit...   \n",
              "1  ['entergy louisiana , llc and subsidiaries man...   \n",
              "2  ['notes to consolidated financial statements n...   \n",
              "3  ['the following is a schedule of future minimu...   \n",
              "4  ['to determine stock-based compensation expens...   \n",
              "\n",
              "                                               table        industry  \\\n",
              "0  [array(['contractual obligations', 'payments d...  Pharmaceutical   \n",
              "1  [array(['2016', '2015', '2014', '2013'], dtype...          Energy   \n",
              "2  [array(['$ in millions', 'as of december 2012'...         Finance   \n",
              "3  [array(['fiscal years', 'operating leases'], d...      Technology   \n",
              "4  [array(['shares in thousands december 31 2013'...         Finance   \n",
              "\n",
              "                                            Combined  \\\n",
              "0  ['( a ) the amount included in 2018 2018less t...   \n",
              "1  ['see note 4 to the financial statements for a...   \n",
              "2  ['rwas under the federal reserve board 2019s r...   \n",
              "3  ['12 .'\\n 'commitments and contingencies from ...   \n",
              "4  ['the pnc financial services group , inc .' '2...   \n",
              "\n",
              "                                      Combined_clean  Lenght_before  \\\n",
              "0  amount included less year reflects anticipated...           4184   \n",
              "1  see note financial statements description mone...           4099   \n",
              "2  rwas federal reserve board riskbased capital r...           4750   \n",
              "3  commitments contingencies time time ordinary c...           2873   \n",
              "4  pnc financial services group inc form determin...           5241   \n",
              "\n",
              "   Lenght_after  industry_label  \n",
              "0          2542               2  \n",
              "1          2876               0  \n",
              "2          3197               1  \n",
              "3          1862               3  \n",
              "4          3457               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-195df1aa-6bfc-400e-8a15-7595cdbe3d79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>post_text</th>\n",
              "      <th>pre_text</th>\n",
              "      <th>table</th>\n",
              "      <th>industry</th>\n",
              "      <th>Combined</th>\n",
              "      <th>Combined_clean</th>\n",
              "      <th>Lenght_before</th>\n",
              "      <th>Lenght_after</th>\n",
              "      <th>industry_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EW/2016/page_50.pdf-2</td>\n",
              "      <td>['( a ) the amount included in 2018 2018less t...</td>\n",
              "      <td>['net cash flows provided by operating activit...</td>\n",
              "      <td>[array(['contractual obligations', 'payments d...</td>\n",
              "      <td>Pharmaceutical</td>\n",
              "      <td>['( a ) the amount included in 2018 2018less t...</td>\n",
              "      <td>amount included less year reflects anticipated...</td>\n",
              "      <td>4184</td>\n",
              "      <td>2542</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ETR/2016/page_352.pdf-3</td>\n",
              "      <td>['see note 4 to the financial statements for a...</td>\n",
              "      <td>['entergy louisiana , llc and subsidiaries man...</td>\n",
              "      <td>[array(['2016', '2015', '2014', '2013'], dtype...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>['see note 4 to the financial statements for a...</td>\n",
              "      <td>see note financial statements description mone...</td>\n",
              "      <td>4099</td>\n",
              "      <td>2876</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GS/2012/page_186.pdf-3</td>\n",
              "      <td>['rwas under the federal reserve board 2019s r...</td>\n",
              "      <td>['notes to consolidated financial statements n...</td>\n",
              "      <td>[array(['$ in millions', 'as of december 2012'...</td>\n",
              "      <td>Finance</td>\n",
              "      <td>['rwas under the federal reserve board 2019s r...</td>\n",
              "      <td>rwas federal reserve board riskbased capital r...</td>\n",
              "      <td>4750</td>\n",
              "      <td>3197</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADI/2011/page_83.pdf-2</td>\n",
              "      <td>['12 .'\\n 'commitments and contingencies from ...</td>\n",
              "      <td>['the following is a schedule of future minimu...</td>\n",
              "      <td>[array(['fiscal years', 'operating leases'], d...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>['12 .'\\n 'commitments and contingencies from ...</td>\n",
              "      <td>commitments contingencies time time ordinary c...</td>\n",
              "      <td>2873</td>\n",
              "      <td>1862</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PNC/2014/page_203.pdf-3</td>\n",
              "      <td>['the pnc financial services group , inc .' '2...</td>\n",
              "      <td>['to determine stock-based compensation expens...</td>\n",
              "      <td>[array(['shares in thousands december 31 2013'...</td>\n",
              "      <td>Finance</td>\n",
              "      <td>['the pnc financial services group , inc .' '2...</td>\n",
              "      <td>pnc financial services group inc form determin...</td>\n",
              "      <td>5241</td>\n",
              "      <td>3457</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-195df1aa-6bfc-400e-8a15-7595cdbe3d79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-195df1aa-6bfc-400e-8a15-7595cdbe3d79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-195df1aa-6bfc-400e-8a15-7595cdbe3d79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0a339f7-987c-47d2-bd47-af429ef85dcd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0a339f7-987c-47d2-bd47-af429ef85dcd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0a339f7-987c-47d2-bd47-af429ef85dcd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1972,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1972,\n        \"samples\": [\n          \"PNC/2014/page_203.pdf-2\",\n          \"JPM/2009/page_183.pdf-4\",\n          \"ADBE/2011/page_116.pdf-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 601,\n        \"samples\": [\n          \"['( 1 ) excludes a loss of $ 94 million expected to be recognized as part of the sale of cartagena , which closed on february 9 , 2012 , and is further discussed in note 23 2014acquisitions and dispositions .'\\n 'the balance in accumulated other comprehensive loss related to derivative transactions will be reclassified into earnings as interest expense is recognized for interest rate hedges and cross currency swaps ( except for the amount reclassified to foreign currency transaction gains and losses to offset the remeasurement of the foreign currency-denominated debt being hedged by the cross currency swaps ) , as depreciation is recognized for interest rate hedges during construction , as foreign currency transaction gains and losses are recognized for hedges of foreign currency exposure , and as electricity sales and fuel purchases are recognized for hedges of forecasted electricity and fuel transactions .'\\n 'these balances are included in the consolidated statements of cash flows as operating and/or investing activities based on the nature of the underlying transaction .'\\n 'for the years ended december 31 , 2011 , 2010 and 2009 , pre-tax gains ( losses ) of $ 0 million , $ ( 1 ) million , and $ 0 million net of noncontrolling interests , respectively , were reclassified into earnings as a result of the discontinuance of a cash flow hedge because it was probable that the forecasted transaction would not occur by the end of the originally specified time period ( as documented at the inception of the hedging relationship ) or within an additional two-month time period thereafter. .']\",\n          \"['( a ) the loews peer group consists of the following companies that are industry competitors of our principal operating subsidiaries : chubb limited ( name change from ace limited after it acquired the chubb corporation on january 15 , 2016 ) , w.r .'\\n 'berkley corporation , the chubb corporation ( included through january 15 , 2016 when it was acquired by ace limited ) , energy transfer partners l.p. , ensco plc , the hartford financial services group , inc. , kinder morgan energy partners , l.p .'\\n '( included through november 26 , 2014 when it was acquired by kinder morgan inc. ) , noble corporation , spectra energy corp , transocean ltd .'\\n 'and the travelers companies , inc .'\\n 'dividend information we have paid quarterly cash dividends in each year since 1967 .'\\n 'regular dividends of $ 0.0625 per share of loews common stock were paid in each calendar quarter of 2016 and 2015. .']\",\n          \"['visa inc .'\\n 'common stock issued in exchange for the acquired interests the value of the purchase consideration conveyed to each of the member groups of the acquired regions was determined by valuing the underlying businesses contributed by each , after giving effect to negotiated adjustments .'\\n 'the fair value of the purchase consideration , consisting of 258022779 shares of class c ( series i ) common stock , was approximately $ 12.6 billion , measured at june 15 , 2007 , or the date on which all parties entered into the global restructuring agreement .'\\n 'additional purchase consideration of $ 1.2 billion , consisting of 26138056 incremental shares of class c common stock valued at $ 44 per share were issued to the acquired regions shortly before the ipo in connection with the true-up .'\\n 'the fair value of these shares was determined based on the price per share in the ipo. .']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pre_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 659,\n        \"samples\": [\n          \"['for the valuation of the 4199466 performance-based options granted in 2005 : the risk free interest rate was 4.2% ( 4.2 % ) , the volatility factor for the expected market price of the common stock was 44% ( 44 % ) , the expected dividend yield was zero and the objective time to exercise was 4.7 years with an objective in the money assumption of 2.95 years .'\\n 'it was also expected that the initial public offering assumption would occur within a 9 month period from grant date .'\\n 'the fair value of the performance-based options was calculated to be $ 5.85 .'\\n 'the fair value for fis options granted in 2006 was estimated at the date of grant using a black-scholes option- pricing model with the following weighted average assumptions .'\\n 'the risk free interest rates used in the calculation are the rate that corresponds to the weighted average expected life of an option .'\\n 'the risk free interest rate used for options granted during 2006 was 4.9% ( 4.9 % ) .'\\n 'a volatility factor for the expected market price of the common stock of 30% ( 30 % ) was used for options granted in 2006 .'\\n 'the expected dividend yield used for 2006 was 0.5% ( 0.5 % ) .'\\n 'a weighted average expected life of 6.4 years was used for 2006 .'\\n 'the weighted average fair value of each option granted during 2006 was $ 15.52 .'\\n 'at december 31 , 2006 , the total unrecognized compensation cost related to non-vested stock option grants is $ 86.1 million , which is expected to be recognized in pre-tax income over a weighted average period of 1.9 years .'\\n 'the company intends to limit dilution caused by option exercises , including anticipated exercises , by repurchasing shares on the open market or in privately negotiated transactions .'\\n 'during 2006 , the company repurchased 4261200 shares at an average price of $ 37.60 .'\\n 'on october 25 , 2006 , the company 2019s board of directors approved a plan authorizing the repurchase of up to an additional $ 200 million worth of the company 2019s common stock .'\\n 'defined benefit plans certegy pension plan in connection with the certegy merger , the company announced that it will terminate and settle the certegy u.s .'\\n 'retirement income plan ( usrip ) .'\\n 'the estimated impact of this settlement was reflected in the purchase price allocation as an increase in the pension liability , less the fair value of the pension plan assets , based on estimates of the total cost to settle the liability through the purchase of annuity contracts or lump sum settlements to the beneficiaries .'\\n 'the final settlement will not occur until after an irs determination has been obtained , which is expected to be received in 2007 .'\\n 'in addition to the net pension plan obligation of $ 21.6 million , the company assumed liabilities of $ 8.0 million for certegy 2019s supplemental executive retirement plan ( 201cserp 201d ) and $ 3.0 mil- lion for a postretirement benefit plan .'\\n 'a reconciliation of the changes in the fair value of plan assets of the usrip for the period from february 1 , 2006 through december 31 , 2006 is as follows ( in thousands ) : .']\",\n          \"['the changes in the gross amount of unrecognized tax benefits for the year ended december 29 , 2007 are as follows: .']\",\n          \"['corporate & institutional banking corporate & institutional banking earned $ 1.9 billion in 2011 and $ 1.8 billion in 2010 .'\\n 'the increase in earnings was primarily due to an improvement in the provision for credit losses , which was a benefit in 2011 , partially offset by a reduction in the value of commercial mortgage servicing rights and lower net interest income .'\\n 'we continued to focus on adding new clients , increasing cross sales , and remaining committed to strong expense discipline .'\\n 'asset management group asset management group earned $ 141 million for 2011 compared with $ 137 million for 2010 .'\\n 'assets under administration were $ 210 billion at december 31 , 2011 and $ 212 billion at december 31 , 2010 .'\\n 'earnings for 2011 reflected a benefit from the provision for credit losses and growth in noninterest income , partially offset by higher noninterest expense and lower net interest income .'\\n 'for 2011 , the business delivered strong sales production , grew high value clients and benefitted from significant referrals from other pnc lines of business .'\\n 'over time and with stabilized market conditions , the successful execution of these strategies and the accumulation of our strong sales performance are expected to create meaningful growth in assets under management and noninterest income .'\\n 'residential mortgage banking residential mortgage banking earned $ 87 million in 2011 compared with $ 269 million in 2010 .'\\n 'the decline in earnings was driven by an increase in noninterest expense associated with increased costs for residential mortgage foreclosure- related expenses , primarily as a result of ongoing governmental matters , and lower net interest income , partially offset by an increase in loan originations and higher loans sales revenue .'\\n 'blackrock our blackrock business segment earned $ 361 million in 2011 and $ 351 million in 2010 .'\\n 'the higher business segment earnings from blackrock for 2011 compared with 2010 were primarily due to an increase in revenue .'\\n 'non-strategic assets portfolio this business segment ( formerly distressed assets portfolio ) consists primarily of acquired non-strategic assets that fall outside of our core business strategy .'\\n 'non-strategic assets portfolio had earnings of $ 200 million in 2011 compared with a loss of $ 57 million in 2010 .'\\n 'the increase was primarily attributable to a lower provision for credit losses partially offset by lower net interest income .'\\n '201cother 201d reported earnings of $ 376 million for 2011 compared with earnings of $ 386 million for 2010 .'\\n 'the decrease in earnings primarily reflected the noncash charge related to the redemption of trust preferred securities in the fourth quarter of 2011 and the gain related to the sale of a portion of pnc 2019s blackrock shares in 2010 partially offset by lower integration costs in 2011 .'\\n 'consolidated income statement review our consolidated income statement is presented in item 8 of this report .'\\n 'net income for 2011 was $ 3.1 billion compared with $ 3.4 billion for 2010 .'\\n 'results for 2011 include the impact of $ 324 million of residential mortgage foreclosure-related expenses primarily as a result of ongoing governmental matters , a $ 198 million noncash charge related to redemption of trust preferred securities and $ 42 million for integration costs .'\\n 'results for 2010 included the $ 328 million after-tax gain on our sale of gis , $ 387 million for integration costs , and $ 71 million of residential mortgage foreclosure-related expenses .'\\n 'for 2010 , net income attributable to common shareholders was also impacted by a noncash reduction of $ 250 million in connection with the redemption of tarp preferred stock .'\\n 'pnc 2019s results for 2011 were driven by good performance in a challenging environment of low interest rates , slow economic growth and new regulations .'\\n 'net interest income and net interest margin year ended december 31 dollars in millions 2011 2010 .']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"table\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 656,\n        \"samples\": [\n          \"[array(['', 'issued', 'in treasury', 'shares outstanding'], dtype=object)\\n array(['balance january 1 2001', '667085793', '-94361099 ( 94361099 )',\\n        '572724694'], dtype=object)\\n array(['employee stock purchase plan', '2013', '1752833', '1752833'],\\n       dtype=object)\\n array(['shares granted to directors', '2013', '4800', '4800'],\\n       dtype=object)\\n array(['shares sold to optionees', '8385', '1399686', '1408071'],\\n       dtype=object)\\n array(['balance december 31 2001', '667094178', '-91203780 ( 91203780 )',\\n        '575890398'], dtype=object)\\n array(['employee stock purchase plan', '2013', '2677842', '2677842'],\\n       dtype=object)\\n array(['shares granted to directors', '2013', '3500', '3500'],\\n       dtype=object)\\n array(['shares sold to optionees', '10490', '2243400', '2253890'],\\n       dtype=object)\\n array(['acquisition of technoguide', '2013', '1347485', '1347485'],\\n       dtype=object)\\n array(['balance december 31 2002', '667104668', '-84931553 ( 84931553 )',\\n        '582173115'], dtype=object)\\n array(['employee stock purchase plan', '2013', '2464088', '2464088'],\\n       dtype=object)\\n array(['shares granted to directors', '2013', '3500', '3500'],\\n       dtype=object)\\n array(['shares sold to optionees', '1320', '1306305', '1307625'],\\n       dtype=object)\\n array(['balance december 31 2003', '667105988', '-81157660 ( 81157660 )',\\n        '585948328'], dtype=object)                                       ]\",\n          \"[array(['', 'year endeddecember 31 2018'], dtype=object)\\n array(['diluted shares', '203.5'], dtype=object)\\n array(['dilutive shares assuming net earnings', '1.5'], dtype=object)\\n array(['adjusted diluted shares', '205.0'], dtype=object)]\",\n          \"[array(['( in millions )', '2006', '2005'], dtype=object)\\n array(['indemnified securities financing', '$ 506032', '$ 372863'],\\n       dtype=object)\\n array(['liquidity asset purchase agreements', '30251', '24412'],\\n       dtype=object)\\n array(['unfunded commitments to extend credit', '16354', '14403'],\\n       dtype=object)\\n array(['standby letters of credit', '4926', '5027'], dtype=object)]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industry\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Energy\",\n          \"Travel\",\n          \"Finance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Combined\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 663,\n        \"samples\": [\n          \"['172 goldman sachs 2016 form 10-k .']['the goldman sachs group , inc .'\\n 'and subsidiaries notes to consolidated financial statements in connection with the firm 2019s prime brokerage and clearing businesses , the firm agrees to clear and settle on behalf of its clients the transactions entered into by them with other brokerage firms .'\\n 'the firm 2019s obligations in respect of such transactions are secured by the assets in the client 2019s account as well as any proceeds received from the transactions cleared and settled by the firm on behalf of the client .'\\n 'in connection with joint venture investments , the firm may issue loan guarantees under which it may be liable in the event of fraud , misappropriation , environmental liabilities and certain other matters involving the borrower .'\\n 'the firm is unable to develop an estimate of the maximum payout under these guarantees and indemnifications .'\\n 'however , management believes that it is unlikely the firm will have to make any material payments under these arrangements , and no material liabilities related to these guarantees and indemnifications have been recognized in the consolidated statements of financial condition as of december 2016 and december 2015 .'\\n 'other representations , warranties and indemnifications .'\\n 'the firm provides representations and warranties to counterparties in connection with a variety of commercial transactions and occasionally indemnifies them against potential losses caused by the breach of those representations and warranties .'\\n 'the firm may also provide indemnifications protecting against changes in or adverse application of certain u.s .'\\n 'tax laws in connection with ordinary-course transactions such as securities issuances , borrowings or derivatives .'\\n 'in addition , the firm may provide indemnifications to some counterparties to protect them in the event additional taxes are owed or payments are withheld , due either to a change in or an adverse application of certain non-u.s .'\\n 'tax laws .'\\n 'these indemnifications generally are standard contractual terms and are entered into in the ordinary course of business .'\\n 'generally , there are no stated or notional amounts included in these indemnifications , and the contingencies triggering the obligation to indemnify are not expected to occur .'\\n 'the firm is unable to develop an estimate of the maximum payout under these guarantees and indemnifications .'\\n 'however , management believes that it is unlikely the firm will have to make any material payments under these arrangements , and no material liabilities related to these arrangements have been recognized in the consolidated statements of financial condition as of december 2016 and december 2015 .'\\n 'guarantees of subsidiaries .' 'group inc .'\\n 'fully and unconditionally guarantees the securities issued by gs finance corp. , a wholly-owned finance subsidiary of the group inc .'\\n 'has guaranteed the payment obligations of goldman , sachs & co .'\\n '( gs&co. ) and gs bank usa , subject to certain exceptions .'\\n 'in addition , group inc .'\\n 'guarantees many of the obligations of its other consolidated subsidiaries on a transaction-by- transaction basis , as negotiated with counterparties .'\\n 'group inc .'\\n 'is unable to develop an estimate of the maximum payout under its subsidiary guarantees ; however , because these guaranteed obligations are also obligations of consolidated subsidiaries , group inc . 2019s liabilities as guarantor are not separately disclosed .'\\n 'note 19 .'\\n 'shareholders 2019 equity common equity dividends declared per common share were $ 2.60 in 2016 , $ 2.55 in 2015 and $ 2.25 in 2014 .'\\n 'on january 17 , 2017 , group inc .'\\n 'declared a dividend of $ 0.65 per common share to be paid on march 30 , 2017 to common shareholders of record on march 2 , 2017 .'\\n 'the firm 2019s share repurchase program is intended to help maintain the appropriate level of common equity .'\\n 'the share repurchase program is effected primarily through regular open-market purchases ( which may include repurchase plans designed to comply with rule 10b5-1 ) , the amounts and timing of which are determined primarily by the firm 2019s current and projected capital position , but which may also be influenced by general market conditions and the prevailing price and trading volumes of the firm 2019s common stock .'\\n 'prior to repurchasing common stock , the firm must receive confirmation that the federal reserve board does not object to such capital actions .'\\n 'the table below presents the amount of common stock repurchased by the firm under the share repurchase program. .'][array(['in millions except per share amounts', 'year ended december 2016',\\n        'year ended december 2015', 'year ended december 2014'],\\n       dtype=object)\\n array(['common share repurchases', '36.6', '22.1', '31.8'], dtype=object)\\n array(['average cost per share', '$ 165.88', '$ 189.41', '$ 171.79'],\\n       dtype=object)\\n array(['total cost of common share repurchases', '$ 6069', '$ 4195',\\n        '$ 5469'], dtype=object)                                     ]\",\n          \"['community reinvestment act exposure the community reinvestment act ( 201ccra 201d ) encourages banks to meet the credit needs of borrowers in all segments of their communities , including neighborhoods with low or moderate incomes .'\\n 'the firm is a national leader in community development by providing loans , investments and community development services in communities across the united states .'\\n 'at december 31 , 2013 and 2012 , the firm 2019s cra loan portfolio was approximately $ 18 billion and $ 16 billion , respectively .'\\n 'at december 31 , 2013 and 2012 , 50% ( 50 % ) and 62% ( 62 % ) , respectively , of the cra portfolio were residential mortgage loans ; 26% ( 26 % ) and 13% ( 13 % ) , respectively , were commercial real estate loans ; 16% ( 16 % ) and 18% ( 18 % ) , respectively , were business banking loans ; and 8% ( 8 % ) and 7% ( 7 % ) , respectively , were other loans .'\\n 'cra nonaccrual loans were 3% ( 3 % ) and 4% ( 4 % ) , respectively , of the firm 2019s total nonaccrual loans .'\\n 'for the years ended december 31 , 2013 and 2012 , net charge-offs in the cra portfolio were 1% ( 1 % ) and 3% ( 3 % ) , respectively , of the firm 2019s net charge-offs in both years. .']['management 2019s discussion and analysis 138 jpmorgan chase & co./2013 annual report the credit derivatives used in credit portfolio management activities do not qualify for hedge accounting under u.s .'\\n 'gaap ; these derivatives are reported at fair value , with gains and losses recognized in principal transactions revenue .'\\n 'in contrast , the loans and lending-related commitments being risk-managed are accounted for on an accrual basis .'\\n 'this asymmetry in accounting treatment , between loans and lending-related commitments and the credit derivatives used in credit portfolio management activities , causes earnings volatility that is not representative , in the firm 2019s view , of the true changes in value of the firm 2019s overall credit exposure .'\\n 'the effectiveness of the firm 2019s credit default swap ( 201ccds 201d ) protection as a hedge of the firm 2019s exposures may vary depending on a number of factors , including the named reference entity ( i.e. , the firm may experience losses on specific exposures that are different than the named reference entities in the purchased cds ) , and the contractual terms of the cds ( which may have a defined credit event that does not align with an actual loss realized by the firm ) and the maturity of the firm 2019s cds protection ( which in some cases may be shorter than the firm 2019s exposures ) .'\\n 'however , the firm generally seeks to purchase credit protection with a maturity date that is the same or similar to the maturity date of the exposure for which the protection was purchased , and remaining differences in maturity are actively monitored and managed by the firm .'\\n 'credit portfolio hedges the following table sets out the fair value related to the firm 2019s credit derivatives used in credit portfolio management activities , the fair value related to the cva ( which reflects the credit quality of derivatives counterparty exposure ) , as well as certain other hedges used in the risk management of cva .'\\n 'these results can vary from period-to- period due to market conditions that affect specific positions in the portfolio .'\\n 'net gains and losses on credit portfolio hedges year ended december 31 , ( in millions ) 2013 2012 2011 hedges of loans and lending- related commitments $ ( 142 ) $ ( 163 ) $ ( 32 ) .'][array(['year ended december 31 ( in millions )', '2013', '2012', '2011'],\\n       dtype=object)\\n array(['hedges of loans and lending-related commitments',\\n        '$ -142 ( 142 )', '$ -163 ( 163 )', '$ -32 ( 32 )'], dtype=object)\\n array(['cva and hedges of cva', '-130 ( 130 )', '127', '-769 ( 769 )'],\\n       dtype=object)\\n array(['net gains/ ( losses )', '$ -272 ( 272 )', '$ -36 ( 36 )',\\n        '$ -801 ( 801 )'], dtype=object)                          ]\",\n          \"['credit facility we are party to a credit facility agreement with bank of america , n.a. , as administrative agent , and a syndicate of financial institutions as lenders and other agents ( as amended from time to time , the 201ccredit facility 201d ) .'\\n 'as of december 31 , 2018 , the credit facility provided for secured financing comprised of ( i ) a $ 1.5 billion revolving credit facility ( the 201crevolving credit facility 201d ) ; ( ii ) a $ 1.5 billion term loan ( the 201cterm a loan 201d ) , ( iii ) a $ 1.37 billion term loan ( the 201cterm a-2 loan 201d ) , ( iv ) a $ 1.14 billion term loan facility ( the 201cterm b-2 loan 201d ) and ( v ) a $ 500 million term loan ( the 201cterm b-4 loan 201d ) .'\\n 'substantially all of the assets of our domestic subsidiaries are pledged as collateral under the credit facility .'\\n 'the borrowings outstanding under our credit facility as of december 31 , 2018 reflect amounts borrowed for acquisitions and other activities we completed in 2018 , including a reduction to the interest rate margins applicable to our term a loan , term a-2 loan , term b-2 loan and the revolving credit facility , an extension of the maturity dates of the term a loan , term a-2 loan and the revolving credit facility , and an increase in the total financing capacity under the credit facility to approximately $ 5.5 billion in june 2018 .'\\n 'in october 2018 , we entered into an additional term loan under the credit facility in the amount of $ 500 million ( the 201cterm b-4 loan 201d ) .'\\n 'we used the proceeds from the term b-4 loan to pay down a portion of the balance outstanding under our revolving credit facility .'\\n 'the credit facility provides for an interest rate , at our election , of either libor or a base rate , in each case plus a margin .'\\n 'as of december 31 , 2018 , the interest rates on the term a loan , the term a-2 loan , the term b-2 loan and the term b-4 loan were 4.02% ( 4.02 % ) , 4.01% ( 4.01 % ) , 4.27% ( 4.27 % ) and 4.27% ( 4.27 % ) , respectively , and the interest rate on the revolving credit facility was 3.92% ( 3.92 % ) .'\\n 'in addition , we are required to pay a quarterly commitment fee with respect to the unused portion of the revolving credit facility at an applicable rate per annum ranging from 0.20% ( 0.20 % ) to 0.30% ( 0.30 % ) depending on our leverage ratio .'\\n 'the term a loan and the term a-2 loan mature , and the revolving credit facility expires , on january 20 , 2023 .'\\n 'the term b-2 loan matures on april 22 , 2023 .'\\n 'the term b-4 loan matures on october 18 , 2025 .'\\n 'the term a loan and term a-2 loan principal amounts must each be repaid in quarterly installments in the amount of 0.625% ( 0.625 % ) of principal through june 2019 , increasing to 1.25% ( 1.25 % ) of principal through june 2021 , increasing to 1.875% ( 1.875 % ) of principal through june 2022 and increasing to 2.50% ( 2.50 % ) of principal through december 2022 , with the remaining principal balance due upon maturity in january 2023 .'\\n 'the term b-2 loan principal must be repaid in quarterly installments in the amount of 0.25% ( 0.25 % ) of principal through march 2023 , with the remaining principal balance due upon maturity in april 2023 .'\\n 'the term b-4 loan principal must be repaid in quarterly installments in the amount of 0.25% ( 0.25 % ) of principal through september 2025 , with the remaining principal balance due upon maturity in october 2025 .'\\n 'we may issue standby letters of credit of up to $ 100 million in the aggregate under the revolving credit facility .'\\n 'outstanding letters of credit under the revolving credit facility reduce the amount of borrowings available to us .'\\n 'borrowings available to us under the revolving credit facility are further limited by the covenants described below under 201ccompliance with covenants . 201d the total available commitments under the revolving credit facility at december 31 , 2018 were $ 783.6 million .'\\n 'global payments inc .' '| 2018 form 10-k annual report 2013 85 .']['maturity requirements on long-term debt as of december 31 , 2018 by year are as follows ( in thousands ) : years ending december 31 .'][array(['2019', '$ 124176'], dtype=object)\\n array(['2020', '159979'], dtype=object)\\n array(['2021', '195848'], dtype=object)\\n array(['2022', '267587'], dtype=object)\\n array(['2023', '3945053'], dtype=object)\\n array(['2024 and thereafter', '475000'], dtype=object)\\n array(['total', '$ 5167643'], dtype=object)]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Combined_clean\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 657,\n        \"samples\": [\n          \"jpmorgan chase co annual report litigation reserve firm maintains litigation reserves certain litigations including material legal proceedings outcome litigation inherently uncertain management believes light information known december firm litigation reserves adequate date management reviews litigation reserves periodically reserves may increased decreased future reflect litigation devel opments firm believes meritorious defenses claims asserted currently outstanding litigation respect liti gation intends continue defend vigorously litigating settling cases according management judgment best interest stockholders note accounting derivative instruments hedging activities derivative instruments enable end users increase reduce alter exposure credit market risks value derivative derived reference underlying variable combination variables equity foreign exchange credit commodity interest rate prices indices jpmorgan chase makes markets derivatives customers also enduser derivatives order manage firm exposure credit market risks sfas amended sfas sfas establishes accounting reporting standards derivative instruments including used trading hedging activities derivative instruments embedded contracts freestanding derivatives whether designated hedging rela tionships required recorded balance sheet fair value accounting changes value derivative depends whether contract trading purposes designated qualifies hedge accounting majority firm derivatives entered trading purposes firm also uses derivatives end user hedge market exposures modify interest rate characteristics related balance sheet instruments meet longerterm investment objectives trading enduser derivatives recorded fair value trading assets trading liabilities set forth note page annual report order qualify hedge accounting derivative must considered highly effective reducing risk associated exposure hedged derivative must designated hedge documentation risk management objective strategy including identification hedging instrument hedged item risk exposure effectiveness assessed prospectively retrospectively extent hedging instrument effective achieving offsetting changes fair value cash flows must assessed least quarterly ineffectiveness must reported currentperiod earnings qualifying fair value hedges changes fair value derivative fair value item risk hedged recognized earnings hedge relationship terminated fair value adjust ment hedged item continues reported part basis item amortized earnings yield adjustment qualifying cash flow hedges effective portion change fair value derivative recorded comprehensive income recognized income statement hedged cash flows affect earnings ineffective portions cash flow hedges immediately recognized earnings hedge relationship terminated change fair value derivative recorded comprehensive income recognized cash flows hedged occur consistent original hedge strategy hedge relationships discontinued forecasted transaction expected occur according original strategy related derivative amounts recorded comprehensive income immediately recognized earnings qualifying net investment hedges changes fair value derivative revaluation foreign currency denominated debt instrument recorded translation adjustments account within comprehensive income ineffective portions net investment hedges immediately recognized earnings jpmorgan chase fair value hedges primarily include hedges fixedrate longterm debt loans afs securities msrs interest rate swaps common type derivative contract used modify exposure interest rate risk converting fixedrate assets liabilities floating rate interest rate options swaptions forwards also used combination interest rate swaps hedge fair value firm msrs discussion msr risk management activities see note pages annual report amounts included earnings consistent classification hedged item primarily net interest income mortgage fees related income income firm recognize gains losses firm commitments longer qualify fair value hedges jpmorgan chase also enters derivative contracts hedge exposure variability cash flows floatingrate financial instruments forecasted transactions primarily rollover shortterm assets liabilities foreign currencydenominated revenues expenses interest rate swaps futures forward contracts common instruments used reduce impact interest rate foreign exchange rate changes future earnings amounts affecting earnings recognized consistent classification hedged item primarily net interest income firm uses forward foreign exchange contracts foreign currency denominated debt instruments protect value net investments foreign currencies nonus subsidiaries portion hedging instru ments excluded assessment hedge effectiveness forward points recorded net interest income following table presents derivative instrument hedgingrelated activities periods indicated year ended december millions fair value hedge ineffective net gains losses cash flow hedge ineffective net gains losses cash flow hedging gains forecasted transactions failed occur results include six months combined firm results six months heritage jpmorgan chase results includes ineffectiveness components hedging instruments excluded assessment hedge effectiveness next months expected million aftertax net gains recorded comprehensive income december recognized earnings maximum length time forecasted transactions hedged years transactions primarily relate core lending borrowing activities jpmorgan chase seek apply hedge accounting firm economic hedges example firm apply hedge accounting standard credit derivatives used manage credit risk loans commitments difficulties qualifying contracts hedges sfas similarly firm apply hedge accounting certain interest rate derivatives used economic hedges jpmorgan chase co annual report litigation reserve firm maintains litigation reserves certain litigations including material legal proceedings outcome litigation inherently uncertain management believes light information known december firm litigation reserves adequate date management reviews litigation reserves periodically reserves may increased decreased future reflect litigation devel opments firm believes meritorious defenses claims asserted currently outstanding litigation respect liti gation intends continue defend vigorously litigating settling cases according management judgment best interest stockholders note accounting derivative instruments hedging activities derivative instruments enable end users increase reduce alter exposure credit market risks value derivative derived reference underlying variable combination variables equity foreign exchange credit commodity interest rate prices indices jpmorgan chase makes markets derivatives customers also enduser derivatives order manage firm exposure credit market risks sfas amended sfas sfas establishes accounting reporting standards derivative instruments including used trading hedging activities derivative instruments embedded contracts freestanding derivatives whether designated hedging rela tionships required recorded balance sheet fair value accounting changes value derivative depends whether contract trading purposes designated qualifies hedge accounting majority firm derivatives entered trading purposes firm also uses derivatives end user hedge market exposures modify interest rate characteristics related balance sheet instruments meet longerterm investment objectives trading enduser derivatives recorded fair value trading assets trading liabilities set forth note page annual report order qualify hedge accounting derivative must considered highly effective reducing risk associated exposure hedged derivative must designated hedge documentation risk management objective strategy including identification hedging instrument hedged item risk exposure effectiveness assessed prospectively retrospectively extent hedging instrument effective achieving offsetting changes fair value cash flows must assessed least quarterly ineffectiveness must reported currentperiod earnings qualifying fair value hedges changes fair value derivative fair value item risk hedged recognized earnings hedge relationship terminated fair value adjust ment hedged item continues reported part basis item amortized earnings yield adjustment qualifying cash flow hedges effective portion change fair value derivative recorded comprehensive income recognized income statement hedged cash flows affect earnings ineffective portions cash flow hedges immediately recognized earnings hedge relationship terminated change fair value derivative recorded comprehensive income recognized cash flows hedged occur consistent original hedge strategy hedge relationships discontinued forecasted transaction expected occur according original strategy related derivative amounts recorded comprehensive income immediately recognized earnings qualifying net investment hedges changes fair value derivative revaluation foreign currency denominated debt instrument recorded translation adjustments account within comprehensive income ineffective portions net investment hedges immediately recognized earnings jpmorgan chase fair value hedges primarily include hedges fixedrate longterm debt loans afs securities msrs interest rate swaps common type derivative contract used modify exposure interest rate risk converting fixedrate assets liabilities floating rate interest rate options swaptions forwards also used combination interest rate swaps hedge fair value firm msrs discussion msr risk management activities see note pages annual report amounts included earnings consistent classification hedged item primarily net interest income mortgage fees related income income firm recognize gains losses firm commitments longer qualify fair value hedges jpmorgan chase also enters derivative contracts hedge exposure variability cash flows floatingrate financial instruments forecasted transactions primarily rollover shortterm assets liabilities foreign currencydenominated revenues expenses interest rate swaps futures forward contracts common instruments used reduce impact interest rate foreign exchange rate changes future earnings amounts affecting earnings recognized consistent classification hedged item primarily net interest income firm uses forward foreign exchange contracts foreign currency denominated debt instruments protect value net investments foreign currencies nonus subsidiaries portion hedging instru ments excluded assessment hedge effectiveness forward points recorded net interest income following table presents derivative instrument hedgingrelated activities periods indicated year ended december millions fair value hedge ineffective net gains losses cash flow hedge ineffective net gains losses cash flow hedging gains forecasted transactions failed occur results include six months combined firm results six months heritage jpmorgan chase results includes ineffectiveness components hedging instruments excluded assessment hedge effectiveness next months expected million aftertax net gains recorded comprehensive income december recognized earnings maximum length time forecasted transactions hedged years transactions primarily relate core lending borrowing activities jpmorgan chase seek apply hedge accounting firm economic hedges example firm apply hedge accounting standard credit derivatives used manage credit risk loans commitments difficulties qualifying contracts hedges sfas similarly firm apply hedge accounting certain interest rate derivatives used economic hedges arrayyear ended december millions dtypeobject arrayfair value hedge ineffective net gains losses dtypeobject arraycash flow hedge ineffective net gains losses dtypeobject arraycash flow hedging gains forecastedtransactions failed occur dtypeobject\",\n          \"carrying value pnc investment blackrock billions includes pnc share blackrock reported gaap earnings additional income taxes earnings incurred pnc december blackrockbarclays global investors transaction december blackrock acquired bgi barclays bank plc exchange approximately billion cash shares blackrock common participating preferred stock connection bgi transaction blackrock entered amendments stockholder agreements pnc major shareholder amendments changed certain shareholder rights including composition blackrock board directors share transfer restrictions became effective upon closing bgi transaction also connection bgi transaction blackrock entered stock purchase agreement pnc purchased shares blackrock series preferred stock price per share million partially finance transaction january series preferred stock converted series preferred stock upon closing bgi transaction carrying value investment blackrock increased significantly reflecting portion increase blackrock equity resulting value blackrock shares issued connection acquisition bgi pnc recognized increase value billion pretax gain fourth quarter december percentage ownership blackrock common stock approximately blackrock ltip programs exchange agreements pnc noninterest income included pretax gains million million related blackrock ltip shares obligation gains represented marktomarket adjustment related remaining blackrock ltip common shares obligation resulted decrease market value blackrock common shares periods previously reported pnc entered exchange agreement blackrock december transactions resulted agreement restructured pnc ownership blackrock equity without altering meaningful extent pnc economic interest blackrock pnc continues subject limitations voting rights existing agreements blackrock also december blackrock entered exchange agreement merrill lynch anticipation consummation merger bank america corporation merrill lynch occurred january pnc merrill lynch exchange agreements restructured pnc merrill lynch respective ownership blackrock common preferred equity exchange contemplated agreements completed february date pnc obligation deliver blackrock common shares replaced obligation deliver shares blackrock new series preferred stock pnc acquired million shares series preferred stock blackrock exchange common shares date pnc accounts preferred shares fair value offsets impact markingtomarket obligation deliver shares blackrock aligned fair value marks asset liability fair value blackrock series preferred stock included consolidated balance sheet assets additional information regarding valuation blackrock series preferred stock included note fair value notes consolidated financial statements included item report pnc accounts remaining investment blackrock equity method accounting share blackrock earnings reduced primarily due exchange blackrock common stock blackrock series preferred stock series preferred stock taken consideration determining pnc share blackrock earnings equity method pnc percentage ownership blackrock common stock increased result substantial exchange merrill lynch blackrock common stock blackrock preferred stock result blackrock preferred stock held merrill lynch new blackrock preferred stock issued merrill lynch pnc exchange agreements pnc share blackrock common stock higher overall share blackrock equity earnings transactions related exchange agreements affect right receive dividends declared blackrock blackrock information related equity investment blackrock follows array dtypeobject arraybusiness segment earnings millions dtypeobject arraypnc share blackrock earnings dtypeobject arraycarrying value pnc investment blackrock billions dtypeobject\",\n          \"cadence completed annual goodwill impairment test third quarter fiscal determined fair value cadence single reporting unit substantially exceeded carrying amount net assets impairment existed note acquisitions fiscal cadence completed two business combinations total cash consideration million taking account cash acquired million total purchase consideration allocated assets acquired liabilities assumed based respective estimated fair values acquisition dates cadence recorded total million acquired intangible assets million represents inprocess technology million goodwill million net liabilities consisting primarily deferred tax liabilities cadence also make payments certain employees subject continued employment performancebased conditions fourth quarter fiscal fiscal cadence completed two business combinations total cash consideration million taking account cash acquired million total purchase consideration allocated assets acquired liabilities assumed based respective estimated fair values acquisition dates cadence recorded total million goodwill million acquired intangible assets million net liabilities consisting primarily deferred revenue cadence also make payments certain employees subject continued employment conditions second quarter fiscal trust benefit children lipbu tan cadence chief executive officer cceo director owned less nusemi inc one companies acquired less rocketick technologies ltd one companies acquired mr tan wife serve cotrustees trust disclaim pecuniary economic interest trust board directors cadence reviewed transactions concluded best interests cadence proceed transactions mr tan recused board directors discussion valuation nusemi inc rocketick technologies ltd whether proceed transactions acquisitionrelated transaction costs direct transaction costs associated acquisitions fiscal transaction costs associated acquisitions million million fiscal respectively costs consist professional fees administrative costs expensed incurred cadence consolidated income statements note goodwill acquired intangibles goodwill changes carrying amount goodwill fiscal follows gross carrying amount thousands array gross carryingamount thousands dtypeobject arraybalance december dtypeobject arraygoodwill resulting acquisitions dtypeobject arrayeffect foreign currency translation dtypeobject arraybalance december dtypeobject arrayeffect foreign currency translation dtypeobject arraybalance december dtypeobject\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lenght_before\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1514,\n        \"min\": 838,\n        \"max\": 16538,\n        \"num_unique_values\": 620,\n        \"samples\": [\n          4981,\n          4282,\n          4239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lenght_after\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1055,\n        \"min\": 448,\n        \"max\": 11765,\n        \"num_unique_values\": 591,\n        \"samples\": [\n          3055,\n          6627,\n          2216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industry_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Train.csv')  # Replace 'unlabeled_data.csv' with the name of your dataset\n",
        "\n",
        "# Preprocess the text data\n",
        "# Implement your text preprocessing steps here\n",
        "\n",
        "# Load the DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenized_texts = [tokenizer(text, return_tensors='pt') for text in df['Combined_clean']]\n",
        "\n",
        "# Concatenate the tokenized tensors\n",
        "input_ids = torch.cat([t['input_ids'] for t in tokenized_texts], dim=0)\n",
        "attention_masks = torch.cat([t['attention_mask'] for t in tokenized_texts], dim=0)\n",
        "\n",
        "# Load the DistilBERT model\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Encode the text data\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "# Get the embeddings\n",
        "embeddings = outputs.last_hidden_state\n",
        "\n",
        "# Perform clustering (example using KMeans)\n",
        "num_clusters = 5  # Number of clusters to create\n",
        "kmeans = KMeans(n_clusters=num_clusters)\n",
        "cluster_labels = kmeans.fit_predict(embeddings)\n",
        "\n",
        "# Analyze the clusters\n",
        "for cluster_id in range(num_clusters):\n",
        "    cluster_indices = cluster_labels == cluster_id\n",
        "    cluster_texts = df.loc[cluster_indices, 'text']\n",
        "    print(f\"Cluster {cluster_id + 1} - Number of samples: {sum(cluster_indices)}\")\n",
        "    print(\"Sample texts:\")\n",
        "    print(cluster_texts.sample(min(5, len(cluster_texts))))\n",
        "    print(\"-----\")"
      ],
      "metadata": {
        "id": "eHG-x1QyQcdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "6c61bcaf-788d-4e6d-ebf9-e8a588a61580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Combined_clean'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Combined_clean'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7bd5bcbd378b>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Tokenize the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtokenized_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Combined_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Concatenate the tokenized tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Combined_clean'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df_train['industry_label'] = le.fit_transform(train_df['Label'])"
      ],
      "metadata": {
        "id": "V0IHI9kFXeMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_train['Combined'].values, df_train['industry_label'].values, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "HaOE4IpSWYcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "bmCEyLu-YTSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = (df_train[['industry','industry_label']].drop_duplicates()\n",
        "              .sort_values(by='industry_label')\n",
        "              .reset_index(drop=True)['industry']\n",
        "              .to_dict())\n",
        "\n",
        "for index, key in label_dict.items():\n",
        "    print(index, key)"
      ],
      "metadata": {
        "id": "gURTwltEXMB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n"
      ],
      "metadata": {
        "id": "NAGMW8SRYrp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate>=0.21.0\n",
        "!pip install transformers>=4.11.3\n",
        "!pip install transformers[torch]\n"
      ],
      "metadata": {
        "id": "FfAv2fXVY16p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17de48fd-fac6-4e56-f02c-e65222fb0f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required libraries (if not already installed)\n",
        "# !pip install transformers\n",
        "\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your preprocessed dataset (replace with your actual data)\n",
        "# Assuming you have 'X_train', 'y_train', 'X_val', and 'y_val'\n",
        "\n",
        "# Load the DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Encode the text data\n",
        "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(train_encodings[\"input_ids\"]),\n",
        "    torch.tensor(train_encodings[\"attention_mask\"]),\n",
        "    torch.tensor(y_train),\n",
        ")\n",
        "val_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(val_encodings[\"input_ids\"]),\n",
        "    torch.tensor(val_encodings[\"attention_mask\"]),\n",
        "    torch.tensor(y_val),\n",
        ")\n",
        "\n",
        "# Load the DistilBERT model for sequence classification\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./distilbert_model\",  # Directory to save the model\n",
        "    per_device_train_batch_size=8,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_steps=500,\n",
        "    logging_dir=\"./logs\",\n",
        "    num_train_epochs=1\n",
        ")\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=lambda data: {\"input_ids\": torch.stack([f[0] for f in data]),\n",
        "                                \"attention_mask\": torch.stack([f[1] for f in data]),\n",
        "                                \"labels\": torch.stack([f[2] for f in data])},\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(\"path/to/save/directory\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEjTYFkAY7eX",
        "outputId": "989979d3-e444-4e34-d431-1a1520d7322d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2651739716529846, 'eval_runtime': 209.3543, 'eval_samples_per_second': 0.946, 'eval_steps_per_second': 0.119, 'epoch': 0.45}\n",
            "{'eval_loss': 0.07931794971227646, 'eval_runtime': 193.5064, 'eval_samples_per_second': 1.023, 'eval_steps_per_second': 0.129, 'epoch': 0.9}\n",
            "{'train_runtime': 7094.877, 'train_samples_per_second': 0.25, 'train_steps_per_second': 0.031, 'train_loss': 0.3859457411207594, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "# Get the predicted labels for the validation dataset\n",
        "y_pred = trainer.predict(val_dataset).predictions.argmax(axis=1)\n",
        "\n",
        "# Get the true labels for the validation dataset\n",
        "y_true = val_dataset[:][2].numpy()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Load the PyTorch model\n",
        "model_path = \"path/to/save/directory\"  # Replace with the path where your model is saved\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Save the model as a .pkl file using pickle\n",
        "with open(\"distilbert_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dapr1tFKY_H3",
        "outputId": "65893c7a-0907-4a8c-d233-5757cf59a0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.07442976534366608, 'eval_runtime': 234.0441, 'eval_samples_per_second': 0.846, 'eval_steps_per_second': 0.107, 'epoch': 1.0}\n",
            "Accuracy: 0.9696969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text ='''Dear manager,\n",
        "I recently had a payment issue while using your company. The reason I was given was \"Due to energy issue, the payment servers were down for a while, we are sorry for the issue, we will ensure this won't happen again.\" The reason was not ok for me, I feel really unsatisfied and energy was not good. If I was travelling some where and I faced this issue, what should I do? If there is a pharmaceutical emergency?? This kind of technological issues should not be happening with such a brand, you have trust of billions of customers, thank you.\n",
        "'''\n",
        "\n",
        "# Preprocess text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get predicted class\n",
        "predicted_class = torch.argmax(outputs.logits).item()\n",
        "\n",
        "# Map predicted class to label\n",
        "labels = [\"Energy\", \"Finance\", \"Pharmaceutical\",\"Technology\",\"Travel\"]  # Replace with your actual class labels\n",
        "predicted_label = labels[predicted_class]\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEKfxSVXZDRN",
        "outputId": "50c69f3d-cc2a-49af-dd8f-4c85a4616844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: Pharmaceutical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bFGSPvlZZqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}